{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DS16 LS_DS_441_RNN_and_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "py37  (Python3)",
      "language": "python",
      "name": "py37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldr0HZ193GKb"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 3, Module 1*\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et2y0gP7IM19"
      },
      "source": [
        "# Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) (Prepare)\n",
        "\n",
        "![](https://wiki.tum.de/download/attachments/22578349/GATES.gif?version=1&modificationDate=1486083227237&api=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BOMScPtIM1-"
      },
      "source": [
        "## Learning Objectives\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IizNKWLomoA"
      },
      "source": [
        "-----\n",
        "# Overview\n",
        "\n",
        "### Let's start with sequences \n",
        "\n",
        "A sequence is just any collection of numbers - order counts and repetition is allowed. \n",
        "\n",
        "Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list and is different from `[1, 2, -1, 2]`. \n",
        "\n",
        "What you might not be as familiar with are recusive numbers. For that, let's talk about a specific example, namely the **Fibonacci Sequence**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44QZgrPUe3-Y"
      },
      "source": [
        "# Neural Networks for Sequences (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX_WLYHrIM1_"
      },
      "source": [
        "\n",
        "\n",
        "Before we dive into the inner workings of an LSTM model, let's try to understand and appreciate the recusive relationships of numbers in both pure mathematics and in the physical reality in which we find ourselves embedded. \n",
        "\n",
        "\n",
        "As usually we take attempt to understand a concept from at least 3 different perspectives:\n",
        "- Algebraic\n",
        "- Geometric\n",
        "- Coding an example\n",
        "\n",
        "\n",
        "A [**recurrence relation**](https://en.wikipedia.org/wiki/Recurrence_relation) in math is an equation that uses recursion to define a sequence of numbers - a famous example is the Fibonacci numbers.\n",
        "\n",
        "Here is the algorithm for generating the numbers in the Fibonacci sequence: \n",
        "\n",
        "$$F_n = F_{n-1} + F_{n-2}$$\n",
        "\n",
        "You need a base case $F_0=1, F_1=1$ (i.e. a starting point) to get the sequence started and then from then on our the sequence is self-generating. \n",
        "\n",
        "So this means that we can start generating our sequence: \n",
        "\n",
        "$$F_0=1,~~  F_1=1 $$\n",
        "\n",
        "$$F_2 = F_{1} + F_{0} ~=~ 1 + 1 ~=~ 2$$\n",
        "\n",
        "Then\n",
        "\n",
        "$$F_3 = F_{2} + F_{1} ~=~ 2 + 1 ~=~ 3$$\n",
        "\n",
        "Then \n",
        "\n",
        "$$F_4 = F_{3} + F_{2} ~=~ 3 + 2 ~=~ 5$$\n",
        "\n",
        "Then \n",
        "\n",
        "$$F_5 = F_{4} + F_{3} ~=~ 5 + 3 ~=~ 8$$\n",
        "\n",
        "I hope you get the idea. \n",
        "\n",
        "Before we we code up this sequence, let's appreciate how important and ubiquitous it is in nature. \n",
        "\n",
        "![](http://www.davidbeahm.com/wp-content/uploads/2011/11/fibonacci-1024x637.jpg)\n",
        "\n",
        "\n",
        "![](https://i.pinimg.com/originals/32/d7/47/32d747bea24f4756dc4c5ffe61b36efd.jpg)\n",
        "\n",
        "![](https://i.pinimg.com/originals/f2/cb/34/f2cb3452dd774bab87bbee2b8a77d4bb.png)\n",
        "\n",
        "\n",
        "![](https://f4.bcbits.com/img/a3628582449_10.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2Zq7yueXchK"
      },
      "source": [
        "**Take Away:** \n",
        "- Recursive sequences are located everywhere in life - but we need to know what we're looking for and where to look for it. \n",
        "- Simply try to develop an appreciation for the connection between mathematics and all of physical reality. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8AkqyEcXchK"
      },
      "source": [
        "### Code up the Fibonacci Sequence\n",
        "Again, here is the algorithm for the Fibonacci numbers.  \n",
        "\n",
        "\n",
        "$$F_n = F_{n-1} + F_{n-2}$$\n",
        "\n",
        "\n",
        "You need a base case to get your sequence started. This time let  $F_0=0 ~\\text{and}~ F_1=1$. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3O4RFb7XchL"
      },
      "source": [
        "def fibo(n):\n",
        "    \"\"\"\n",
        "    Calculate and return the next number in the Fibonacci sequence\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    n: int or float\n",
        "        The nth number in the sequence (think of it as an index for a list)\n",
        "        \n",
        "    Return\n",
        "    ------\n",
        "    F_n: the next number in the sequence generated from the previous two numbers in the sequence \n",
        "    \"\"\"\n",
        "    \n",
        "    if n <= 1:\n",
        "        # if n = 0, then return 0 \n",
        "        return n\n",
        "    else:\n",
        "        # this is the recursive part \n",
        "        # notice how the function is a function of itself!\n",
        "        #  F_n =       F_n-1 + F_n-2\n",
        "        return(fibo(n-1) + fibo(n-2))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d5757486eecafe9c2c1af5b428e482b3",
          "grade": false,
          "grade_id": "cell-b31ecb0aaf3ace76",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Wvufk2s6XchL",
        "outputId": "c9d9b628-6e79-4c34-ed8a-3f1adf15ee59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# generate a Fibonacci Sequence\n",
        "# YOUR CODE HERE\n",
        "fibo(9)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5h76EKZXchM"
      },
      "source": [
        "**Take Away:** \n",
        "\n",
        "Recursive algorithms have as input their previous output. In order words, the output at time step `t - 1`, becomes in the input in the following time step `t`. This is the key idea of that you should observe. Because it is this recursive behavior that is new to how we will think about neural networks, specifically the LSTM model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk1Gbk40XchM"
      },
      "source": [
        "-----\n",
        "\n",
        "## Introduction to Recursive Neural Networks (RNNs) \n",
        "\n",
        "\n",
        "The nice thing about spending time to understand the Fibonacci Sequence is that we can then `borrow the intuition` that we picked up to help us understand how the LSTM works. \n",
        "\n",
        "Different Recursive Neural Networks (RNNs) have this recursive loop in their architecture. The ML research community first created the following RNN model using the standard Fully-Connected Forward Feeding (FCFF) model: \n",
        "\n",
        "![](https://nerdthecoder.files.wordpress.com/2019/02/731df-0mrhhgabskajpbt21.png)\n",
        "\n",
        "`This type of RNN had severe limitations!` \n",
        "\n",
        "- It didn't have long-term memory capacity to learn long input sequences \n",
        "- It suffered from the [Vanishing Gradient Problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem).\n",
        "\n",
        "In response to these limitations, the ML research community created the LSTM model, which ditched the FCFF architecture and started using the following architecture:\n",
        "\n",
        "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
        "\n",
        "Wow! Ok! There's a lot going on here, isn't there? Well, don't worry, we are going to break this model down bit-by-bit so we can understand what is happening. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x_weaCkXchN"
      },
      "source": [
        "_____\n",
        "\n",
        "\n",
        "## Theory of LSTM\n",
        "\n",
        "One of the simplist and clearest explanations of the LSTM model can be found [**here!**](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) - a beautifully clear and concise explaination the model's archtecture and the mathematics. This link will serve as our main resouce for understanding how LSTMs work. \n",
        "\n",
        "Below are the equations for each of the gates that are explained in the article. \n",
        "\n",
        "Although, you will not be held responsible for the equations in any quiz, module assignment, or Sprint Challenge - it is still instructive to be exposed to them at least once.\n",
        "\n",
        "First thing to notice is that each gate equation (not the cell states) has the form of a perceptron. \n",
        "\n",
        "`Remember the perceptron?` It's the fundamental building block of neural networks - it's not going away! \n",
        "\n",
        "Once you understand that, it will hopefully become gradually clear that each gate is a perceptron with a different job to do. \n",
        "\n",
        "That's it. \n",
        "\n",
        "It's just 4 perceptrons, each with a different job to do. \n",
        "\n",
        "Fortunately, you already know about perceptrons (you built one from scratch in `Sprint 2 Module 1`). \n",
        "\n",
        "____\n",
        "\n",
        "### Gates in More Detail\n",
        "\n",
        "#### Forget Gate\n",
        "This neuron's job is to use the current input to learn what information the cell state should forget regarding long-term dependencies. \n",
        "\n",
        "\n",
        "$$f_t = \\sigma(W_f \\cdot [h_{t-1},x_t]~+~b_f)$$\n",
        "\n",
        "#### Input Gate\n",
        "This neuron's job is to use the current input to learn what new information to include in the cell state. \n",
        "\n",
        "\n",
        "$$i_t = \\sigma(W_i \\cdot [h_{t-1},x_t]~+~b_i)$$\n",
        "\n",
        "#### Candidate Cell State \n",
        "This neuron's job is to use the current input to create a candidate cell state.\n",
        "\n",
        "This new candidate cell state will be used to update the model's final cell state.\n",
        "\n",
        "$$\\tilde{C}_t = \\text{tanh}(W_C \\cdot [h_{t-1},x_t]~+~b_C)$$\n",
        "\n",
        "#### New Cell State\n",
        "This is where the candidate and old cell state are combined to create a new cell state.\n",
        "\n",
        "This is where output from the forget gate $f_t$ is used to scaled the old cell state\n",
        "\n",
        "- If $f_t$'s value is closer to 0.0, then less information from the previous cell state is retained.\n",
        "- If $f_t$'s value is closer to 1.0, then more information from the previous cell state is retained. \n",
        "\n",
        "\n",
        "This is also where the output of the input gate $i_t$ is used to scaled the candidate cell state. \n",
        "- If $i_t$'s value is closer to 0.0, then less information from the candidate cell state is retained\n",
        "- If $i_t$'s value is closer to 1.0, then more information from the candidate cell state is retained. \n",
        "\n",
        "Finally, you combine the two scaled cell states to form the new cell state of the model. \n",
        "\n",
        "It is $C_t$ that will be passed into the next training step and used by the output to make a final prediction. \n",
        "\n",
        "$$C_t = f_t*C_{t-1} + i_t*\\tilde{C}_t$$\n",
        "\n",
        "#### Output Gate\n",
        "This is where the actual output of the model is calcuated. \n",
        "\n",
        "The article denotes the model's pre-scaled output as $o_t$ and the scaled output as $h_t$. To be clear, it is $h_t$ that ultimately gets outputed as the model's final prediction. \n",
        "\n",
        "We are familiar with the notation $y$ to denote a model's prediction instead of using $h$. But they both mean the same thing - the model's final prediction. \n",
        "\n",
        "This neuron's job is to take the current input and make a prediction. \n",
        "\n",
        "$$o_t = \\sigma(W_o \\cdot [h_{t-1},x_t]~+~b_o)$$\n",
        "\n",
        "Next, the cell state is used to inform the final prediction. \n",
        "\n",
        "Recall that $o_t$ is output from a sigmoid activation function, so it's value is somewhere between 0 and 1. \n",
        "\n",
        "Which means that it is being used to scale $\\text{tanh}(C_t)$ which contains the current cell state. \n",
        "\n",
        "Recall the tanh curve and you'll see that tanh is scaling $C_t$ so that it's value lies between -1 and 1; this makes it possible to have positive and negative values for the model's output. Sigmoids don't allow for the posibility of negative values, but tanh does. \n",
        "\n",
        "$$h_t = o_t*\\text{tanh}(C_t)$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLaKCb20XchO"
      },
      "source": [
        "_________\n",
        "\n",
        "### Today's Application of LSTMs\n",
        "\n",
        "So why are these cool? \n",
        "\n",
        "One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
        "\n",
        "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. \n",
        "\n",
        "Resources:\n",
        "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
        "- https://keras.io/layers/recurrent/#lstm\n",
        "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
        "\n",
        "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWrQllf8WEd-"
      },
      "source": [
        "_____________\n",
        "\n",
        "\n",
        "## Follow Along\n",
        "\n",
        "Sequences come in many shapes and forms from stock prices to text. We'll focus on text, because modeling text as a sequence is a strength of Neural Networks. Let's start with a simple classification task using a TensorFlow tutorial. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSytcRhoIM2A"
      },
      "source": [
        "### RNN/LSTM Sentiment Classification with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti23G0gRe3kr"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, Dropout, Flatten\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.datasets import imdb\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7NsCB2PXchP",
        "outputId": "c84e1930-d302-4dca-d4e2-212498e15748"
      },
      "source": [
        "# load in dataset \n",
        "\n",
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000 train sequences\n",
            "25000 test sequences\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XWP9TNEM8-q"
      },
      "source": [
        "# documentation on this data set here: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data\n",
        "# the values in the lists represents the token frequncy, so \"1\" means the most frequent token in the corpus \n",
        "# each list represents a movie review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK9k4UKJM9EC"
      },
      "source": [
        "# binary labels \n",
        "# 1 -> positive sentiment expressed in movie review\n",
        "# 0 -> negative sentiment expressed in movie review "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "c0awRJCnIM2G",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "06de4d9b7986caa5aef6c537af138ee9",
          "grade": false,
          "grade_id": "cell-fb23c1d7d1168a73",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# although there are some implmentations of LSTM models that can handle variable length samples, this is not one of those models\n",
        "# so we need to standardize the length of our movies\n",
        "# reviews that are longer than maxlen are truncated\n",
        "# reivewsd that are shorter than maxlen are padded with 0 (Or some other value that you provide)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riMcgC9lXchQ"
      },
      "source": [
        "### Build a 1 hidden layer LSTM language model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "QD_NjHw-pcJS",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "200cc0a64ca234e836bf8fe83a553143",
          "grade": false,
          "grade_id": "cell-9c285c5d84213905",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# YOUR CODE HERE\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics='accuracy')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHjt-VTTXchR",
        "outputId": "a0c71533-eb3a-4807-9111-a5c041dabef7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results_one_layer = model.fit(x_train, y_train,\n",
        "                      batch_size=256, \n",
        "                      epochs=5, \n",
        "                      validation_data=(x_test,y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "98/98 [==============================] - 5s 38ms/step - loss: 0.6836 - accuracy: 0.5484 - val_loss: 0.6792 - val_accuracy: 0.5549\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 4s 36ms/step - loss: 0.6744 - accuracy: 0.5637 - val_loss: 0.6794 - val_accuracy: 0.5555\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 4s 36ms/step - loss: 0.6720 - accuracy: 0.5660 - val_loss: 0.6801 - val_accuracy: 0.5554\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 4s 36ms/step - loss: 0.6710 - accuracy: 0.5666 - val_loss: 0.6807 - val_accuracy: 0.5556\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 4s 36ms/step - loss: 0.6703 - accuracy: 0.5675 - val_loss: 0.6817 - val_accuracy: 0.5552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2sGSwavXchR"
      },
      "source": [
        "### Build a 1 hidden layer Bidirectional LSTM language model\n",
        "\n",
        "A Bidirectional LSTM, or biLSTM, is a sequence processing model that consists of two LSTMs: **one taking the input in a forward direction**, and **the other in a backwards direction**. BiLSTMs effectively increase the amount of information available to the network, improving the context available to the algorithm (e.g. knowing what words immediately follow and precede a word in a sentence).\n",
        "\n",
        "![](https://miro.medium.com/max/764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "cKyGb4TzIM2O",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b7058ca0b8f53f28530be9c93a8bef46",
          "grade": false,
          "grade_id": "cell-706b7be103484984",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# YOUR CODE HERE\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V430JwVeXchR",
        "outputId": "1b527915-a3ae-4730-958f-040910898299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results_biLSTM = model.fit(x_train, y_train,\n",
        "                      batch_size=256, \n",
        "                      epochs=20, \n",
        "                      validation_data=(x_test,y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "98/98 [==============================] - 11s 71ms/step - loss: 0.4842 - accuracy: 0.7559 - val_loss: 0.3943 - val_accuracy: 0.8288\n",
            "Epoch 2/20\n",
            "98/98 [==============================] - 5s 53ms/step - loss: 0.2713 - accuracy: 0.8934 - val_loss: 0.3946 - val_accuracy: 0.8294\n",
            "Epoch 3/20\n",
            "98/98 [==============================] - 5s 53ms/step - loss: 0.1811 - accuracy: 0.9339 - val_loss: 0.4140 - val_accuracy: 0.8210\n",
            "Epoch 4/20\n",
            "98/98 [==============================] - 5s 53ms/step - loss: 0.1176 - accuracy: 0.9602 - val_loss: 0.5308 - val_accuracy: 0.8134\n",
            "Epoch 5/20\n",
            "98/98 [==============================] - 5s 54ms/step - loss: 0.0732 - accuracy: 0.9773 - val_loss: 0.6926 - val_accuracy: 0.8020\n",
            "Epoch 6/20\n",
            "98/98 [==============================] - 5s 53ms/step - loss: 0.0534 - accuracy: 0.9834 - val_loss: 0.7345 - val_accuracy: 0.8028\n",
            "Epoch 7/20\n",
            "98/98 [==============================] - 5s 52ms/step - loss: 0.0390 - accuracy: 0.9882 - val_loss: 0.7667 - val_accuracy: 0.7993\n",
            "Epoch 8/20\n",
            "98/98 [==============================] - 5s 53ms/step - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.9750 - val_accuracy: 0.7948\n",
            "Epoch 9/20\n",
            "98/98 [==============================] - 5s 53ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 0.9475 - val_accuracy: 0.7974\n",
            "Epoch 10/20\n",
            "98/98 [==============================] - 5s 52ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.9754 - val_accuracy: 0.7982\n",
            "Epoch 11/20\n",
            "98/98 [==============================] - 5s 53ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 1.0899 - val_accuracy: 0.7962\n",
            "Epoch 12/20\n",
            "98/98 [==============================] - 5s 52ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 1.0124 - val_accuracy: 0.7990\n",
            "Epoch 13/20\n",
            "98/98 [==============================] - 5s 53ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 1.0523 - val_accuracy: 0.7974\n",
            "Epoch 14/20\n",
            "98/98 [==============================] - 5s 52ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 1.0346 - val_accuracy: 0.7983\n",
            "Epoch 15/20\n",
            "98/98 [==============================] - 5s 55ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 1.1001 - val_accuracy: 0.7968\n",
            "Epoch 16/20\n",
            "98/98 [==============================] - 5s 54ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 1.1493 - val_accuracy: 0.7960\n",
            "Epoch 17/20\n",
            "98/98 [==============================] - 5s 55ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 1.0261 - val_accuracy: 0.7960\n",
            "Epoch 18/20\n",
            "98/98 [==============================] - 5s 54ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 1.2092 - val_accuracy: 0.7971\n",
            "Epoch 19/20\n",
            "98/98 [==============================] - 5s 55ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 1.1137 - val_accuracy: 0.8028\n",
            "Epoch 20/20\n",
            "98/98 [==============================] - 5s 55ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 1.0335 - val_accuracy: 0.7964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "RZx3Zs7tIM2Q",
        "outputId": "fc911f3d-9a4c-44e3-a8fd-ab5e94f41d6c"
      },
      "source": [
        "# Plot training & validation loss values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch_list = np.arange(1,6)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.grid()\n",
        "plt.xticks(epoch_list)\n",
        "# results for 1-layer lstm model\n",
        "plt.plot(epoch_list, results_one_layer.history['loss'], \"--\", label=\"1 layer Train\")\n",
        "plt.plot(epoch_list, results_one_layer.history['val_loss'], \"--\", label = \"1 layer Test\")\n",
        "\n",
        "# results for 3-layer lstm model\n",
        "plt.plot(epoch_list, results_biLSTM.history['loss'], label=\"biLSTM Train \")\n",
        "plt.plot(epoch_list, results_biLSTM.history['val_loss'], label = \"biLSTM Test\")A\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7cebf59b9eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# results for 3-layer lstm model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_biLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"biLSTM Train \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_biLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"biLSTM Test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (20,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Ps3CauIM2S"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pETWPIe362y"
      },
      "source": [
        "--------\n",
        "# LSTM Text generation with Keras (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZRese-wXchS"
      },
      "source": [
        "Using sequential models to generate text data is a very popular application of recursive deep learning models. A couple of popular applications are [**chat bots**](https://hackernoon.com/deep-learning-chatbot-everything-you-need-to-know-r11jm30bc) and language translators such as [**google translate**](https://ai.googleblog.com/2020/06/recent-advances-in-google-translate.html). \n",
        "\n",
        "In order to properly build a chat bot or translater you need to use multiple lstm models in an encoder & decoder framwork known as a [**sequence 2 sequence model**](https://keras.io/examples/nlp/lstm_seq2seq/) .\n",
        "\n",
        "\n",
        "![](https://jeddy92.github.io/images/ts_intro/seq2seq_lang.png)\n",
        "\n",
        "Also, now a days, using a standard LSTM isn't enough. You also have to use a version of lstm seq2seq models known as [**transformers**](https://towardsdatascience.com/transformers-141e32e69591). Transformers give seq2seq models the capacity to pay attention to specific portions of the input sequence, the most relevent portion in order to make a prediction. Yes, that's right, humanity has figured out how to convert attention into an algorithm. Next stop, self-awareness! \n",
        "\n",
        "The above mentions of sequence 2 sequence models and transformers are for a larger contextual understanding of the landscape of language models and how LSTMs fit into this landscape. Although **we will cover the endcoder/decoder framework in a future lesson, transformers are outside the scope of Unit 4**. However, once you learn about LSTMs and encoder/decoder frameworks, you will have all necessary information to then go on and learn about transformers on your own. At that point, the only really new bit you'll be learning is the [**attention mechanism**](https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f). \n",
        "\n",
        "\n",
        "As a first pass at text generation, we'll stick to standard LSTM models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK-GrUGvIM2T"
      },
      "source": [
        "-----\n",
        "# Text Generation using LSTMs\n",
        "\n",
        "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
        "\n",
        "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q64qHEYIIM2U"
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_6L5aGzXchT"
      },
      "source": [
        "# a custom data prep class that we'll be using \n",
        "from data_cleaning_toolkit_class import data_cleaning_toolkit"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MxcXsdsSIM2W",
        "outputId": "f1587f87-be53-4626-e459-cd1e0f4b23e2"
      },
      "source": [
        "# load text data (articles)\n",
        "df = pd.read_json('https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/wp_articles.json')\n",
        "df.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Contributing columnist\\n\\nThe House is on fire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When President Trump announced his decision to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Russian President Vladimir Putin speaks at a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>The Queens Speech is designed to acknowledg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Like an aging rock star, the president is now ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               article\n",
              "0    Contributing columnist\\n\\nThe House is on fire...\n",
              "1    When President Trump announced his decision to...\n",
              "10   Russian President Vladimir Putin speaks at a s...\n",
              "100  The Queens Speech is designed to acknowledg...\n",
              "101  Like an aging rock star, the president is now ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "54b3f47f5eeed6cf3fd9732ac8abf1e5",
          "grade": false,
          "grade_id": "cell-292d1e2b08c74976",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Nw5sCCVvXchT"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "# Create the sequence data\n",
        "text = \" \".join(df['article'])\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmAFuTWzuxW4"
      },
      "source": [
        "encoded = [char_int[c] for c in text]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAjL3rAuuy_W",
        "outputId": "9f1ea4b8-933f-4871-fab3-554378e9f9c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(encoded)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "891910"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPCQc8_fuVv5"
      },
      "source": [
        "sequences = []\n",
        "next_char = []\n",
        "\n",
        "for i in range(0, len(encoded) -maxlen, step):\n",
        "  sequences.append(encoded[i: i+maxlen])\n",
        "  next_char.append(encoded[i+maxlen])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7--WAdavrvL",
        "outputId": "002ddb4c-2e53-431c-8b47-317ec3780fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# sequences[0]\n",
        "int_char[next_char[0]]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'f'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgZe1KJDy_zM"
      },
      "source": [
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b46715962d32c041b4849afdf6c87232",
          "grade": false,
          "grade_id": "cell-6a39513d81d87f1b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "qQHWAMKzXchT"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "# raise NotImplementedError()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape = (maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation = 'softmax'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WihvCiUXchT"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Helper function to sample an index from a probability array\n",
        "    \"\"\"\n",
        "    # convert preds to array \n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    # scale values \n",
        "    preds = np.log(preds) / temperature\n",
        "    # exponentiate values\n",
        "    exp_preds = np.exp(preds)\n",
        "    # this equation should look familar to you (hint: it's an activation function)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    # Draw samples from a multinomial distribution\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    # return the index that corresponds to the max probability \n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgPJ6s_zzQxw"
      },
      "source": [
        "# create callback object that will print out text generation at the end of each epoch \n",
        "# use for real-time monitoring of model performance\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncu87VtAxzoW",
        "outputId": "fb4b4935-aee4-426e-a579-607d29e190f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# YOUR CODE HERE\n",
        "model.fit(x, y, \n",
        "          batch_size=32,\n",
        "          epochs = 10,\n",
        "          callbacks = [print_callback])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5575/5575 [==============================] - 30s 5ms/step - loss: 0.0339 - accuracy: 0.2227\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"horities.\n",
            "\n",
            "At the Foreign Ministry, spo\"\n",
            "horities.\n",
            "\n",
            "At the Foreign Ministry, spower4iveKSom terd Mke the ted the perccatwlldt arklalrd rilad lin alacs trer 1tr thathitolFled dajf Aho hedy Iord er Tr the juco thagWce thillor hot thalecyering thotiele tovatiE mut ta ksor he Cf ures de stache ghot of theut. Worma akl hortponce tot. ping danor ay thbe thap phe-eng lue a wd anthe tharinay and thl worilas asthe dogd thavith unmy ticttenl dtheacaps aostil gay 3ilparly ine [ngsi\n",
            "Epoch 2/10\n",
            "5575/5575 [==============================] - 28s 5ms/step - loss: 0.0279 - accuracy: 0.3067\n",
            "\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"ase called MegaFace. Now some of those f\"\n",
            "ase called MegaFace. Now some of those fofte thect caverkqursay an th. al )tet beticess tot the sougsonnllar-ast om rushase 1OHas pamlingeng the coprice: fol bermerse 1couss bloucenysors wsolct wo tin sode for ar eas cosedcecyore the ncornmtylly clarite, arel .0-pathense bubuse igess caste shiof . rewtrond on that wily ge ooyemint mactar-fase cathindisanegrely buu cep wipkaller. (orle laug orte watrunts poted l-oel, whals fort isurs o\n",
            "Epoch 3/10\n",
            "5575/5575 [==============================] - 28s 5ms/step - loss: 0.0265 - accuracy: 0.3384\n",
            "\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"after which the possibility of the game \"\n",
            "after which the possibility of the game tha dent sthehen and app nemscomit wats at on the Winw sack ovexteall, We froicy, a fores, Bxiening aw the wis app ap adettou dasicg stl hin the operes ane pombl in pormenccoun. 296s Renperteds that cobmureas, enal, the Cryoring then pouby hath sgoty coplant an the siwer. Hont U?ELsump ha oncaating oup op meperld the turiention.\n",
            "\n",
            "The ato bias the ation a 1man tor cout as a whem gefonsingale Kexe\n",
            "Epoch 4/10\n",
            "5575/5575 [==============================] - 28s 5ms/step - loss: 0.0255 - accuracy: 0.3650\n",
            "\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \" And it was not an accident. The log, so\"\n",
            " And it was not an accident. The log, sountearer the been lita tho werk the reaed Zyourbois, the 1620 be, meviont os of ching in the cas leation an be coactrons in forlicer of the ghatee the celmiee ssent the SSabe sppering. He may Trease the aldntymo extoring on besorstericilass and moke the (hepriminger Pame Cloccaters sovtint om: Ind the as the the istiod momby of offyer stored in Wetown bot the fistertountesting at the her Frops do \n",
            "Epoch 5/10\n",
            "5575/5575 [==============================] - 29s 5ms/step - loss: 0.0248 - accuracy: 0.3829\n",
            "\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"on: They announced a deal with the Syria\"\n",
            "on: They announced a deal with the Syriady cand. You but to (praod desalled it ; Ruple, for ho Uning the 24: Ind ake hoon theme 50 pantarse un the way at the buppreded, and ic ploon which winy in the Rascous madingrers of the Mos. 1-Trus, the limes the Vackey an you can Parncons in the Rancctares the coubhad of Chearite Und so sece you lolmition dopaly wain. Lmand suaduch ppat to mugars in Gumpandence diflesel calla in the ate Toup Mive\n",
            "Epoch 6/10\n",
            "5575/5575 [==============================] - 29s 5ms/step - loss: 0.0242 - accuracy: 0.3997\n",
            "\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"lan officials were given the lengthier s\"\n",
            "lan officials were given the lengthier segs ally acceabian for the Trumpay. Bus hos dearlans and Deast and ano-thoogg: coscented and nome, eextable of storging and of Kirs athronst uching in a retor: thights mation Ma.)\n",
            "\n",
            "Hown whe ervortitatis lawter as pare Brigat of the malust coppaction exto injoution exoctarg pardectill and blansLiss, some inclis, ackers but and Mesion ay plite hilling mantage by is as dysizent fonle your gaid sen\n",
            "Epoch 7/10\n",
            "5575/5575 [==============================] - 29s 5ms/step - loss: 0.0237 - accuracy: 0.4125\n",
            "\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"eeping transformation of the American ec\"\n",
            "eeping transformation of the American ecent to with with mirs, he oficistion of Surfirled marlef the douns ofem the gaimbouth and swith lued and cresiggr gamber a drist-wink aboctod the firnstor Bits you 19Sy spastion entorial and sied , 21-& a relicisted filt-ry coull and hrecorvation aidermant ackiotrorgt quake was books. Apports it & 20-sestire Play of rurfermmation Issemonions was wister betching do gapon Mows Inat gould kerught to\n",
            "Epoch 8/10\n",
            "5575/5575 [==============================] - 29s 5ms/step - loss: 0.0233 - accuracy: 0.4240\n",
            "\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"o do something big tonight,  Altuve sa\"\n",
            "o do something big tonight,  Altuve said worded Pwetsued You invobonal Refent jolical Ruars aransed in in Marizequatentel it the igster and fents alles wint laid. Copeces os the ad Fousing wSong has wast proving Losup (Netehe counttic, frat the peppost be the becess comp of chele ty the pirent and with of mister. AP at her their mideld the to with dide, weshormate Deash his pacime on Conforme cone the Prast the tand Moldor aroupet i\n",
            "Epoch 9/10\n",
            "5575/5575 [==============================] - 29s 5ms/step - loss: 0.0230 - accuracy: 0.4330\n",
            "\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"ially decided his appeal or before all 1\"\n",
            "ially decided his appeal or before all 15 erequed in it the morense and Tourrient as decom treen and a peasunce  why rileather gaingly and I net exset carreshan ownday leame the leassuent are by the as mares. All  not of centriar, have in the souble corvel the Handify hto clecive in everyid in a retolial intraule of (Arkbauble hin acteme way Russing furntrile Distory sairlush Hon remoted and Wanker the saine the book-3-y a songea give\n",
            "Epoch 10/10\n",
            "5575/5575 [==============================] - 30s 5ms/step - loss: 0.0227 - accuracy: 0.4404\n",
            "\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"n. Several more rallies are planned over\"\n",
            "n. Several more rallies are planned over that the sercent redust prong us eascle roundes forlys and atter live you ade may am peokec werting teast of the wown On stares the Mien Bougine of the kinf mongt on comens to has plased the lowel docue the peraed the resection hand recient the homp or the Yor goies he able sime the proude readies so the is a stalled whoce hom broom soned in been have in reported the desome wouth as hoo lual, saq\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92a7401850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkDHWdvKXchU",
        "outputId": "0fda2b7f-d359-465c-c0c6-eb0a056676b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "# need this for on_epoch_end()\n",
        "text = \" \".join(data)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-53e51008f3cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# need this for on_epoch_end()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0BFtoKUIM2x"
      },
      "source": [
        "# create callback object that will print out text generation at the end of each epoch \n",
        "# use for real-time monitoring of model performance\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmoAhwGLXchU"
      },
      "source": [
        "---------\n",
        "### Build Text Generating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "p7XeGd0a2MKi",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f6cb82e3e8cab149b063e8a7705aeae9",
          "grade": false,
          "grade_id": "cell-0b9d84be1c960668",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBt5ugHKIM21"
      },
      "source": [
        "-------------\n",
        "## Challenge\n",
        "\n",
        "You will be expected to use a Keras LSTM to generate text on today's assignment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ger33u0CIM22"
      },
      "source": [
        "# Review\n",
        "\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "    * Sequence Problems:\n",
        "        - Time Series (like Stock Prices, Weather, etc.)\n",
        "        - Text Classification\n",
        "        - Text Generation\n",
        "        - And many more! :D\n",
        "    * LSTMs are generally preferred over RNNs for most problems\n",
        "    * LSTMs are typically a single hidden layer of LSTM type; although, other architectures are possible.\n",
        "    * Keras has LSTMs/RNN layer types implemented nicely\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras\n",
        "    * Shape of input data is very important\n",
        "    * Can take a while to train\n",
        "    * You can use it to write movie scripts. :P "
      ]
    }
  ]
}